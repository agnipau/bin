#!/usr/bin/env python

import requests
from time import sleep
import sys

TIMEOUT_SECS = 2
USERNAME = sys.argv[1]
USER_AGENT = 'Mozilla/5.0 (X11; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0'

def fetch_posts(after):
    url = f'https://www.reddit.com/user/{USERNAME}/submitted.json?type=links&limit=100'
    if after is not None:
        url += '&after=' + after
    resp = requests.get(url,
                        headers={'User-Agent': USER_AGENT})
    return resp.json()['data']

after = None
while True:
    if after is not None:
        sys.stderr.write(f'Timeout of {TIMEOUT_SECS} secs\n')
        sleep(TIMEOUT_SECS)

    sys.stderr.write(f'Fetching after={after}\n')
    resp = fetch_posts(after)
    after = resp['after']
    if after is None:
        sys.stderr.write('Received after=None, exiting')
        break
    for child in map(lambda x: x['data'], resp['children']):
        if child['subreddit'] == 'RedditSessions' and child['link_flair_text'] == 'Broadcast':
            print(child['id'])
